# -*- mode: ruby -*-
# vi: set ft=ruby :

unless Vagrant.has_plugin?('nugrant')
  warn "[\e[1m\e[31mERROR\e[0m]: Please run: vagrant plugin install nugrant"
  exit -1
end

BRIDGE_NETWORK = '10.1.0.100'
SLAVE_NETWORK = '10.1.0.%s'
BRIDGE_NETMASK = '255.255.0.0'

def setup_defaults()
  {
      'appserver' => {
          'name' => 'aControl - Application Server',
          'cpus' => '2',
          'memory' => '2048'
      },
      'slave' => {
          'instances' => 2,
          'name' => 'aControl - Application Slave',
          'cpus' => '1',
          'memory' => '1024'
      },
      'worker' => {
          'instances' => 2,
          'name' => 'aControl - Application Worker',
          'cpus' => '2',
          'memory' => '2048'
      },
      'customize' => ['modifyvm', :id,
                      '--nicpromisc2', 'allow-all',
                      '--groups', '/aControl Reporting System'],
      'gui' => false,
      'box' => 'ubuntu/trusty64'
  }
end

Vagrant.configure(2) do |config|
  # Load configurations
  config.user.defaults = setup_defaults

  # Enable ssh forward agent
  config.ssh.forward_agent = true

  # Create Application server
  # ------------------------------------------------------------------------------------------------
  config.vm.define :appserver, {:primary => true} do |ah|

    ah.vm.hostname = :appserver
    ah.vm.box = config.user.box

    # Synced folders
    ah.vm.synced_folder './../../acontrol-web/src', '/usr/share/nginx/web', :disabled => false # path to application
    ah.vm.synced_folder './../../', '/application-host', :disabled => false # path to application

    # Network
    ah.vm.network :private_network, :ip => BRIDGE_NETWORK, :netmask => BRIDGE_NETMASK

    # Port for ssh
    ah.vm.network :forwarded_port, guest: 22, host: 2220, id: "ssh" # ssh

    # Supervisor
    ah.vm.network :forwarded_port, guest: 9001, host: 9000 # supervisor

    # Nginx as web server and load balancer
    ah.vm.network :forwarded_port, guest: 9999, host: 9999 # nginx

    # Master redis
    ah.vm.network :forwarded_port, guest: 6379, host: 6379 # redis
    ah.vm.network :forwarded_port, guest: 8081, host: 6100 # redis-commander

    # Spark master
    ah.vm.network :forwarded_port, guest: 7077, host: 7077 # spark
    ah.vm.network :forwarded_port, guest: 8080, host: 8080 # spark

    # VM configuration
    ah.vm.provider :virtualbox do |vb|
      vb.name = config.user.appserver.name

      vb.memory = config.user.appserver.memory
      vb.cpus = config.user.appserver.cpus

      vb.gui = config.user.gui

      vb.customize config.user.customize
    end

    # The following line terminates all ssh connections. Therefore
    # Vagrant will be forced to reconnect.
    # That's a workaround to have the docker command in the PATH and
    # add Vagrant to the docker group by logging in/out
    ah.vm.provision :shell, :inline => "ps aux | grep 'sshd:' | awk '{print $2}' | xargs kill"

    ah.vm.provision :ansible do |ansible|
      ansible.playbook = "../application-host.yml"
    end
  end

  # Create Application servers
  # ------------------------------------------------------------------------------------------------
  config.user.slave.instances.downto(1) do |slave|

    # Create Application slave
    config.vm.define "slave-#{slave}", {:primary => false} do |sl|

      sl.vm.hostname = "slave-#{slave}"
      sl.vm.box = config.user.box

      # Synced folders
      sl.vm.synced_folder './../../', '/application-host', :disabled => false # path to application

      # Network
      sl.vm.network :private_network, :ip => SLAVE_NETWORK % [200 + slave], :netmask => BRIDGE_NETMASK

      # Port for ssh
      sl.vm.network :forwarded_port, guest: 22, host: 2220 + slave, id: "ssh" # ssh

      # Supervisor
      sl.vm.network :forwarded_port, guest: 9001, host: 9000 + slave # supervisor

      # Slave redis
      sl.vm.network :forwarded_port, guest: 6379, host: 6000 + slave # redis
      sl.vm.network :forwarded_port, guest: 8081, host: 6100 + slave # redis-commander

      sl.vm.network :forwarded_port, guest: 9900, host: 9900 + slave # reporting-api

      # VM configuration
      sl.vm.provider :virtualbox do |vb|
        vb.name = "#{config.user.slave.name} #{slave}"

        vb.memory = config.user.slave.memory
        vb.cpus = config.user.slave.cpus

        vb.gui = config.user.gui

        vb.customize config.user.customize
      end

      # The following line terminates all ssh connections. Therefore
      # Vagrant will be forced to reconnect.
      # That's a workaround to have the docker command in the PATH and
      # add Vagrant to the docker group by logging in/out
      sl.vm.provision :shell, :inline => "ps aux | grep 'sshd:' | awk '{print $2}' | xargs kill"

      sl.vm.provision :ansible do |ansible|
        ansible.playbook = "../slave-host.yml"
      end
    end
  end

  # Create Application workers
  # ------------------------------------------------------------------------------------------------
  config.user.worker.instances.downto(1) do |worker|

    # Create Application worker
    config.vm.define "worker-#{worker}", {:primary => false} do |wk|

      wk.vm.hostname = "worker-#{worker}"
      wk.vm.box = config.user.box

      # Synced folders
      wk.vm.synced_folder './../../', '/application-host', :disabled => false # path to application

      # Network
      wk.vm.network :private_network, :ip => SLAVE_NETWORK % [230 + worker], :netmask => BRIDGE_NETMASK

      # Port for ssh
      wk.vm.network :forwarded_port, guest: 22, host: 2230 + worker, id: "ssh" # ssh

      # Supervisor
      wk.vm.network :forwarded_port, guest: 9001, host: 9030 + worker # supervisor

      # Spark
      wk.vm.network :forwarded_port, guest: 8081, host: 8080 + worker # spark


      # VM configuration
      wk.vm.provider :virtualbox do |vb|
        vb.name = "#{config.user.worker.name} #{worker}"

        vb.memory = config.user.worker.memory
        vb.cpus = config.user.worker.cpus

        vb.gui = config.user.gui

        vb.customize config.user.customize
      end

      # The following line terminates all ssh connections. Therefore
      # Vagrant will be forced to reconnect.
      # That's a workaround to have the docker command in the PATH and
      # add Vagrant to the docker group by logging in/out
      wk.vm.provision :shell, :inline => "ps aux | grep 'sshd:' | awk '{print $2}' | xargs kill"

      wk.vm.provision :ansible do |ansible|
        ansible.playbook = "../worker-host.yml"
      end
    end
  end
end
